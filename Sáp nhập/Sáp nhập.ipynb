{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unicode\n",
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def detailed_unicode_diff(s1, s2):\n",
    "    s1_norm = normalize_unicode(s1)\n",
    "    s2_norm = normalize_unicode(s2)\n",
    "\n",
    "    max_len = max(len(s1_norm), len(s2_norm))\n",
    "    diffs = []\n",
    "\n",
    "    for i in range(max_len):\n",
    "        c1 = s1_norm[i] if i < len(s1_norm) else \"[EMPTY]\"\n",
    "        c2 = s2_norm[i] if i < len(s2_norm) else \"[EMPTY]\"\n",
    "        u1 = f\"U+{ord(c1):04X}\" if c1 != \"[EMPTY]\" else \"-\"\n",
    "        u2 = f\"U+{ord(c2):04X}\" if c2 != \"[EMPTY]\" else \"-\"\n",
    "\n",
    "        if c1 != c2:\n",
    "            diffs.append(\n",
    "                f\"❌ Pos {i+1}: '{c1}' ({u1}) ≠ '{c2}' ({u2})\"\n",
    "            )\n",
    "        else:\n",
    "            diffs.append(\n",
    "                f\"✅ Pos {i+1}: '{c1}' ({u1})\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pos 1: 'P' (U+0050)\n",
      "✅ Pos 2: 'h' (U+0068)\n",
      "✅ Pos 3: 'ư' (U+01B0)\n",
      "✅ Pos 4: 'ờ' (U+1EDD)\n",
      "✅ Pos 5: 'n' (U+006E)\n",
      "✅ Pos 6: 'g' (U+0067)\n",
      "✅ Pos 7: ' ' (U+0020)\n",
      "✅ Pos 8: 'A' (U+0041)\n",
      "✅ Pos 9: 'n' (U+006E)\n",
      "✅ Pos 10: ' ' (U+0020)\n",
      "✅ Pos 11: 'T' (U+0054)\n",
      "✅ Pos 12: 'r' (U+0072)\n",
      "✅ Pos 13: 'ư' (U+01B0)\n",
      "✅ Pos 14: 'ờ' (U+1EDD)\n",
      "✅ Pos 15: 'n' (U+006E)\n",
      "✅ Pos 16: 'g' (U+0067)\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Phường An Trường\"\n",
    "s2 = \"Phường An Trường\"\n",
    "print(detailed_unicode_diff(s1, s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_unicode_diff(str1, str2):\n",
    "    print(f'{\"Pos\":<5}{\"Str1\":<10}{\"Code1\":<8}{\"Str2\":<10}{\"Code2\":<8}Status')\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    for i in range(max_len):\n",
    "        ch1 = str1[i] if i < len(str1) else ''\n",
    "        ch2 = str2[i] if i < len(str2) else ''\n",
    "        code1 = ord(ch1) if ch1 else '-'\n",
    "        code2 = ord(ch2) if ch2 else '-'\n",
    "        status = 'OK' if ch1 == ch2 and code1 == code2 else 'DM'\n",
    "        print(f'{i+1:<5}{repr(ch1):<10}{code1!s:<8}{repr(ch2):<10}{code2!s:<8}{status}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos  Str1      Code1   Str2      Code2   Status\n",
      "1    'P'       80      'P'       80      OK\n",
      "2    'h'       104     'h'       104     OK\n",
      "3    'ư'       432     'ư'       432     OK\n",
      "4    'ơ'       417     'ờ'       7901    DM\n",
      "5    '̀'       768     'n'       110     DM\n",
      "6    'n'       110     'g'       103     DM\n",
      "7    'g'       103     ' '       32      DM\n",
      "8    ' '       32      'H'       72      DM\n",
      "9    'H'       72      'ả'       7843    DM\n",
      "10   'a'       97      'i'       105     DM\n",
      "11   '̉'       777     ' '       32      DM\n",
      "12   'i'       105     'V'       86      DM\n",
      "13   ' '       32      'â'       226     DM\n",
      "14   'V'       86      'n'       110     DM\n",
      "15   'â'       226     ''        -       DM\n",
      "16   'n'       110     ''        -       DM\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Phường Hải Vân\"\n",
    "s2 = \"Phường Hải Vân\"\n",
    "\n",
    "analyze_unicode_diff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized text\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: Xã Vị BìnhHuyện Vị ThuỷHậu Giang\n",
      "Sau   : Xa Vi BinhHuyen Vi ThuyHau Giang\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    # Normalize về dạng NFD (tách chữ cái và dấu)\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    # Loại bỏ các ký tự thuộc nhóm dấu (Mn = Mark, Nonspacing)\n",
    "    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    # Normalize lại nếu cần\n",
    "    return unicodedata.normalize('NFC', text)\n",
    "\n",
    "text = \"Xã Vị BìnhHuyện Vị ThuỷHậu Giang\"\n",
    "text_no_diacritics = remove_vietnamese_diacritics(text)\n",
    "\n",
    "print(\"Trước:\", text)\n",
    "print(\"Sau   :\", text_no_diacritics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        CP  \\\n",
      "0  Thị trấn Phó BảngHuyện Đồng VănHà Giang   \n",
      "1   Xã Hố Quáng PhìnHuyện Đồng VănHà Giang   \n",
      "2       Xã Thuận HoàHuyện Vị XuyênHà Giang   \n",
      "3    Xã Túng SánHuyện Hoàng Su PhìHà Giang   \n",
      "4      Xã Nậm TỵHuyện Hoàng Su PhìHà Giang   \n",
      "\n",
      "                                Addresses  \\\n",
      "0     Thị trấn An PhúHuyện An PhúAn Giang   \n",
      "1  Thị trấn Long BìnhHuyện An PhúAn Giang   \n",
      "2         Xã Khánh AnHuyện An PhúAn Giang   \n",
      "3       Xã Khánh BìnhHuyện An PhúAn Giang   \n",
      "4         Xã Nhơn HộiHuyện An PhúAn Giang   \n",
      "\n",
      "                           A_no_diacritics  \\\n",
      "0  Thi tran Pho BangHuyen Đong VanHa Giang   \n",
      "1   Xa Ho Quang PhinHuyen Đong VanHa Giang   \n",
      "2       Xa Thuan HoaHuyen Vi XuyenHa Giang   \n",
      "3    Xa Tung SanHuyen Hoang Su PhiHa Giang   \n",
      "4      Xa Nam TyHuyen Hoang Su PhiHa Giang   \n",
      "\n",
      "                          B_no_diacritics  is_match_no_diacritics  \n",
      "0     Thi tran An PhuHuyen An PhuAn Giang                   False  \n",
      "1  Thi tran Long BinhHuyen An PhuAn Giang                   False  \n",
      "2         Xa Khanh AnHuyen An PhuAn Giang                   False  \n",
      "3       Xa Khanh BinhHuyen An PhuAn Giang                   False  \n",
      "4         Xa Nhon HoiHuyen An PhuAn Giang                   False  \n",
      "✅ Đã xuất kết quả tại: E:\\githubb\\TungProject\\result_Normalized_text.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Hàm bỏ dấu tiếng Việt\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "file_path = r\"E:\\githubb\\TungProject\\Normalized text.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2 cột A và B\n",
    "df[\"A_no_diacritics\"] = df[\"CP\"].apply(remove_vietnamese_diacritics)\n",
    "df[\"B_no_diacritics\"] = df[\"Addresses\"].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# So sánh \n",
    "df[\"is_match_no_diacritics\"] = df[\"A_no_diacritics\"] == df[\"B_no_diacritics\"]\n",
    "print(df[[\"CP\", \"Addresses\", \"A_no_diacritics\", \"B_no_diacritics\", \"is_match_no_diacritics\"]].head())\n",
    "\n",
    "output_path = r\"E:\\githubb\\TungProject\\result_Normalized_text.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Đã xuất kết quả tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Chuyển về Rad để tính hàm haversine\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    # Set bán kính trái đất= 6371\n",
    "    R = 6371.0  \n",
    "    \n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    return R * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source\n",
    "df = pd.read_excel(r\"C:\\Users\\tungdt174\\Documents\\GitHub\\MyProjectt\\tungdt174\\Tesst KC cac diem TP Hue.xlsx\")\n",
    "df = df.dropna(subset=[\"Lat\", \"Lng\"])   \n",
    "\n",
    "rows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Khoảng cách\n",
    "for i, row_i in df.iterrows():\n",
    "    name_i, lat_i, lng_i = row_i[\"Điểm\"], row_i[\"Lat\"], row_i[\"Lng\"]\n",
    "    temp = []\n",
    "\n",
    "    for j, row_j in df.iterrows():\n",
    "        if i == j:\n",
    "            continue\n",
    "        name_j, lat_j, lng_j = row_j[\"Điểm\"], row_j[\"Lat\"], row_j[\"Lng\"]\n",
    "        dist = haversine(lat_i, lng_i, lat_j, lng_j)\n",
    "        temp.append((name_j, round(dist, 2)))\n",
    "\n",
    "    temp_sorted = sorted(temp, key=lambda x: x[1])[:4]\n",
    "\n",
    "    result = {\"Phường/Xã\": name_i}\n",
    "    for k in range(4):\n",
    "        result[f\"Gần nhất {k+1}\"] = temp_sorted[k][0]\n",
    "        result[f\"Khoảng cách {k+1} (km)\"] = temp_sorted[k][1]\n",
    "    rows.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(rows)\n",
    "df_out.to_excel(\"top4_gan_nhat_phuongxa_hue.xlsx\", index=False)\n",
    "print(\"Result 'top4_gan_nhat_phuongxa_hue.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataCleaning**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

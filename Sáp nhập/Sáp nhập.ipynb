{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unicode\n",
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def detailed_unicode_diff(s1, s2):\n",
    "    s1_norm = normalize_unicode(s1)\n",
    "    s2_norm = normalize_unicode(s2)\n",
    "\n",
    "    max_len = max(len(s1_norm), len(s2_norm))\n",
    "    diffs = []\n",
    "\n",
    "    for i in range(max_len):\n",
    "        c1 = s1_norm[i] if i < len(s1_norm) else \"[EMPTY]\"\n",
    "        c2 = s2_norm[i] if i < len(s2_norm) else \"[EMPTY]\"\n",
    "        u1 = f\"U+{ord(c1):04X}\" if c1 != \"[EMPTY]\" else \"-\"\n",
    "        u2 = f\"U+{ord(c2):04X}\" if c2 != \"[EMPTY]\" else \"-\"\n",
    "\n",
    "        if c1 != c2:\n",
    "            diffs.append(\n",
    "                f\"❌ Pos {i+1}: '{c1}' ({u1}) ≠ '{c2}' ({u2})\"\n",
    "            )\n",
    "        else:\n",
    "            diffs.append(\n",
    "                f\"✅ Pos {i+1}: '{c1}' ({u1})\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"An Trường\"\n",
    "s2 = \"An Trường\"\n",
    "\n",
    "print(detailed_unicode_diff(s1, s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_unicode_diff(str1, str2):\n",
    "    print(f'{\"Pos\":<5}{\"Str1\":<10}{\"Code1\":<8}{\"Str2\":<10}{\"Code2\":<8}Status')\n",
    "    max_len = max(len(str1), len(str2))\n",
    "    for i in range(max_len):\n",
    "        ch1 = str1[i] if i < len(str1) else ''\n",
    "        ch2 = str2[i] if i < len(str2) else ''\n",
    "        code1 = ord(ch1) if ch1 else '-'\n",
    "        code2 = ord(ch2) if ch2 else '-'\n",
    "        status = 'OK' if ch1 == ch2 and code1 == code2 else 'DM'\n",
    "        print(f'{i+1:<5}{repr(ch1):<10}{code1!s:<8}{repr(ch2):<10}{code2!s:<8}{status}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos  Str1      Code1   Str2      Code2   Status\n",
      "1    'A'       65      'A'       65      OK\n",
      "2    'n'       110     'n'       110     OK\n",
      "3    ' '       32      ' '       32      OK\n",
      "4    'T'       84      'T'       84      OK\n",
      "5    'r'       114     'r'       114     OK\n",
      "6    'ư'       432     'ư'       432     OK\n",
      "7    'ờ'       7901    'ơ'       417     DM\n",
      "8    'n'       110     '̀'       768     DM\n",
      "9    'g'       103     'n'       110     DM\n",
      "10   ''        -       'g'       103     DM\n"
     ]
    }
   ],
   "source": [
    "s1 = \"An Trường\"\n",
    "s2 = \"An Trường\"\n",
    "\n",
    "analyze_unicode_diff(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized text\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: Xã Vị BìnhHuyện Vị ThuỷHậu Giang\n",
      "Sau   : Xa Vi BinhHuyen Vi ThuyHau Giang\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    # Normalize về dạng NFD (tách chữ cái và dấu)\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    # Loại bỏ các ký tự thuộc nhóm dấu (Mn = Mark, Nonspacing)\n",
    "    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    # Normalize lại nếu cần\n",
    "    return unicodedata.normalize('NFC', text)\n",
    "\n",
    "text = \"Xã Vị BìnhHuyện Vị ThuỷHậu Giang\"\n",
    "text_no_diacritics = remove_vietnamese_diacritics(text)\n",
    "\n",
    "print(\"Trước:\", text)\n",
    "print(\"Sau   :\", text_no_diacritics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        CP  \\\n",
      "0  Thị trấn Phó BảngHuyện Đồng VănHà Giang   \n",
      "1   Xã Hố Quáng PhìnHuyện Đồng VănHà Giang   \n",
      "2       Xã Thuận HoàHuyện Vị XuyênHà Giang   \n",
      "3    Xã Túng SánHuyện Hoàng Su PhìHà Giang   \n",
      "4      Xã Nậm TỵHuyện Hoàng Su PhìHà Giang   \n",
      "\n",
      "                                Addresses  \\\n",
      "0     Thị trấn An PhúHuyện An PhúAn Giang   \n",
      "1  Thị trấn Long BìnhHuyện An PhúAn Giang   \n",
      "2         Xã Khánh AnHuyện An PhúAn Giang   \n",
      "3       Xã Khánh BìnhHuyện An PhúAn Giang   \n",
      "4         Xã Nhơn HộiHuyện An PhúAn Giang   \n",
      "\n",
      "                           A_no_diacritics  \\\n",
      "0  Thi tran Pho BangHuyen Đong VanHa Giang   \n",
      "1   Xa Ho Quang PhinHuyen Đong VanHa Giang   \n",
      "2       Xa Thuan HoaHuyen Vi XuyenHa Giang   \n",
      "3    Xa Tung SanHuyen Hoang Su PhiHa Giang   \n",
      "4      Xa Nam TyHuyen Hoang Su PhiHa Giang   \n",
      "\n",
      "                          B_no_diacritics  is_match_no_diacritics  \n",
      "0     Thi tran An PhuHuyen An PhuAn Giang                   False  \n",
      "1  Thi tran Long BinhHuyen An PhuAn Giang                   False  \n",
      "2         Xa Khanh AnHuyen An PhuAn Giang                   False  \n",
      "3       Xa Khanh BinhHuyen An PhuAn Giang                   False  \n",
      "4         Xa Nhon HoiHuyen An PhuAn Giang                   False  \n",
      "✅ Đã xuất kết quả tại: E:\\githubb\\TungProject\\result_Normalized_text.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Hàm bỏ dấu tiếng Việt\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "file_path = r\"E:\\githubb\\TungProject\\Normalized text.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# 2 cột A và B\n",
    "df[\"A_no_diacritics\"] = df[\"CP\"].apply(remove_vietnamese_diacritics)\n",
    "df[\"B_no_diacritics\"] = df[\"Addresses\"].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# So sánh \n",
    "df[\"is_match_no_diacritics\"] = df[\"A_no_diacritics\"] == df[\"B_no_diacritics\"]\n",
    "print(df[[\"CP\", \"Addresses\", \"A_no_diacritics\", \"B_no_diacritics\", \"is_match_no_diacritics\"]].head())\n",
    "\n",
    "output_path = r\"E:\\githubb\\TungProject\\result_Normalized_text.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Đã xuất kết quả tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataCleaning**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

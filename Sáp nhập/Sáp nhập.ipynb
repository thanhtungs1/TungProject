{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unicode\n",
    "import unicodedata\n",
    "\n",
    "def normalize_unicode(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    return unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "def detailed_unicode_diff(s1, s2):\n",
    "    s1_norm = normalize_unicode(s1)\n",
    "    s2_norm = normalize_unicode(s2)\n",
    "\n",
    "    max_len = max(len(s1_norm), len(s2_norm))\n",
    "    diffs = []\n",
    "\n",
    "    for i in range(max_len):\n",
    "        c1 = s1_norm[i] if i < len(s1_norm) else \"[EMPTY]\"\n",
    "        c2 = s2_norm[i] if i < len(s2_norm) else \"[EMPTY]\"\n",
    "        u1 = f\"U+{ord(c1):04X}\" if c1 != \"[EMPTY]\" else \"-\"\n",
    "        u2 = f\"U+{ord(c2):04X}\" if c2 != \"[EMPTY]\" else \"-\"\n",
    "\n",
    "        if c1 != c2:\n",
    "            diffs.append(\n",
    "                f\"❌ Pos {i+1}: '{c1}' ({u1}) ≠ '{c2}' ({u2})\"\n",
    "            )\n",
    "        else:\n",
    "            diffs.append(\n",
    "                f\"✅ Pos {i+1}: '{c1}' ({u1})\"\n",
    "            )\n",
    "\n",
    "    return \"\\n\".join(diffs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pos 1: 'X' (U+0058)\n",
      "✅ Pos 2: 'ã' (U+00E3)\n",
      "✅ Pos 3: ' ' (U+0020)\n",
      "✅ Pos 4: 'V' (U+0056)\n",
      "✅ Pos 5: 'ị' (U+1ECB)\n",
      "✅ Pos 6: ' ' (U+0020)\n",
      "✅ Pos 7: 'B' (U+0042)\n",
      "✅ Pos 8: 'ì' (U+00EC)\n",
      "✅ Pos 9: 'n' (U+006E)\n",
      "✅ Pos 10: 'h' (U+0068)\n",
      "✅ Pos 11: 'H' (U+0048)\n",
      "✅ Pos 12: 'u' (U+0075)\n",
      "✅ Pos 13: 'y' (U+0079)\n",
      "✅ Pos 14: 'ệ' (U+1EC7)\n",
      "✅ Pos 15: 'n' (U+006E)\n",
      "✅ Pos 16: ' ' (U+0020)\n",
      "✅ Pos 17: 'V' (U+0056)\n",
      "✅ Pos 18: 'ị' (U+1ECB)\n",
      "✅ Pos 19: ' ' (U+0020)\n",
      "✅ Pos 20: 'T' (U+0054)\n",
      "✅ Pos 21: 'h' (U+0068)\n",
      "❌ Pos 22: 'u' (U+0075) ≠ 'ủ' (U+1EE7)\n",
      "❌ Pos 23: 'ỷ' (U+1EF7) ≠ 'y' (U+0079)\n",
      "✅ Pos 24: 'H' (U+0048)\n",
      "✅ Pos 25: 'ậ' (U+1EAD)\n",
      "✅ Pos 26: 'u' (U+0075)\n",
      "✅ Pos 27: ' ' (U+0020)\n",
      "✅ Pos 28: 'G' (U+0047)\n",
      "✅ Pos 29: 'i' (U+0069)\n",
      "✅ Pos 30: 'a' (U+0061)\n",
      "✅ Pos 31: 'n' (U+006E)\n",
      "✅ Pos 32: 'g' (U+0067)\n"
     ]
    }
   ],
   "source": [
    "s1 = \"Xã Vị BìnhHuyện Vị ThuỷHậu Giang\"\n",
    "s2 = \"Xã Vị BìnhHuyện Vị ThủyHậu Giang\"\n",
    "\n",
    "print(detailed_unicode_diff(s1, s2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized text\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# Load\n",
    "file_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\Test unicode.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Bỏ dấu\n",
    "if \"I\" in df.columns:\n",
    "    df[\"I_no_diacritics\"] = df[\"I\"].apply(remove_vietnamese_diacritics)\n",
    "else:\n",
    "    colname = df.columns[8]\n",
    "    df[colname + \"_no_diacritics\"] = df[colname].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# Xuất\n",
    "output_path = r\"C:\\Users\\tungdt174\\Documents\\GitHub\\TungProject\\output_no_diacritics.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ File đã lưu tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trước: Xã Vị BìnhHuyện Vị ThuỷHậu Giang\n",
      "Sau   : Xa Vi BinhHuyen Vi ThuyHau Giang\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    # Normalize về dạng NFD (tách chữ cái và dấu)\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    # Loại bỏ các ký tự thuộc nhóm dấu (Mn = Mark, Nonspacing)\n",
    "    text = ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "    # Normalize lại nếu cần\n",
    "    return unicodedata.normalize('NFC', text)\n",
    "\n",
    "text = \"Xã Vị BìnhHuyện Vị ThuỷHậu Giang\"\n",
    "text_no_diacritics = remove_vietnamese_diacritics(text)\n",
    "\n",
    "print(\"Trước:\", text)\n",
    "print(\"Sau   :\", text_no_diacritics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        CP  \\\n",
      "0  Thị trấn Phó BảngHuyện Đồng VănHà Giang   \n",
      "1   Xã Hố Quáng PhìnHuyện Đồng VănHà Giang   \n",
      "2       Xã Thuận HoàHuyện Vị XuyênHà Giang   \n",
      "3    Xã Túng SánHuyện Hoàng Su PhìHà Giang   \n",
      "4      Xã Nậm TỵHuyện Hoàng Su PhìHà Giang   \n",
      "\n",
      "                                Addresses  \\\n",
      "0     Thị trấn An PhúHuyện An PhúAn Giang   \n",
      "1  Thị trấn Long BìnhHuyện An PhúAn Giang   \n",
      "2         Xã Khánh AnHuyện An PhúAn Giang   \n",
      "3       Xã Khánh BìnhHuyện An PhúAn Giang   \n",
      "4         Xã Nhơn HộiHuyện An PhúAn Giang   \n",
      "\n",
      "                           A_no_diacritics  \\\n",
      "0  Thi tran Pho BangHuyen Đong VanHa Giang   \n",
      "1   Xa Ho Quang PhinHuyen Đong VanHa Giang   \n",
      "2       Xa Thuan HoaHuyen Vi XuyenHa Giang   \n",
      "3    Xa Tung SanHuyen Hoang Su PhiHa Giang   \n",
      "4      Xa Nam TyHuyen Hoang Su PhiHa Giang   \n",
      "\n",
      "                          B_no_diacritics  is_match_no_diacritics  \n",
      "0     Thi tran An PhuHuyen An PhuAn Giang                   False  \n",
      "1  Thi tran Long BinhHuyen An PhuAn Giang                   False  \n",
      "2         Xa Khanh AnHuyen An PhuAn Giang                   False  \n",
      "3       Xa Khanh BinhHuyen An PhuAn Giang                   False  \n",
      "4         Xa Nhon HoiHuyen An PhuAn Giang                   False  \n",
      "✅ Đã xuất kết quả tại: E:\\githubb\\TungProject\\result_Normalized_text.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# ✅ Hàm bỏ dấu tiếng Việt\n",
    "def remove_vietnamese_diacritics(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize('NFD', str(text))\n",
    "    return ''.join([c for c in text if unicodedata.category(c) != 'Mn'])\n",
    "\n",
    "# ✅ Load file Excel\n",
    "file_path = r\"E:\\githubb\\TungProject\\Normalized text.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# ✅ Xử lý bỏ dấu cho 2 cột A và B\n",
    "df[\"A_no_diacritics\"] = df[\"CP\"].apply(remove_vietnamese_diacritics)\n",
    "df[\"B_no_diacritics\"] = df[\"Addresses\"].apply(remove_vietnamese_diacritics)\n",
    "\n",
    "# ✅ So sánh sau khi bỏ dấu\n",
    "df[\"is_match_no_diacritics\"] = df[\"A_no_diacritics\"] == df[\"B_no_diacritics\"]\n",
    "\n",
    "# ✅ In ra vài dòng đầu\n",
    "print(df[[\"CP\", \"Addresses\", \"A_no_diacritics\", \"B_no_diacritics\", \"is_match_no_diacritics\"]].head())\n",
    "\n",
    "# ✅ (Tùy chọn) Xuất ra file Excel kết quả\n",
    "output_path = r\"E:\\githubb\\TungProject\\result_Normalized_text.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(\"✅ Đã xuất kết quả tại:\", output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataCleaning**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

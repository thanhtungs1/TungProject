{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.remote.webelement import WebElement\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from selenium.webdriver.common.action_chains import ActionChains, ScrollOrigin\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from selenium.webdriver.chrome.options import Options  \n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))\n",
    "sys.path.insert(0, parent_dir)\n",
    "\n",
    "from db_manipulator import insert_update_data\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "provinces = [\n",
    "    'ho-chi-minh', 'ha-noi', 'da-nang','can-tho','hai-phong','hue','khanh-hoa','dong-nai','nghe-an','vung-tau',\n",
    "    'an-giang','bac-lieu','bac-giang','bac-ninh','ben-tre','binh-duong','binh-dinh','binh-phuoc',\n",
    "    'binh-thuan','ca-mau','dak-lak','dien-bien','dong-thap'\n",
    "]\n",
    "categories = ['food', 'fresh']\n",
    "urls = [f\"https://shopeefood.vn/{province}/{cat}/deals\" for province in provinces for cat in categories]\n",
    "\n",
    "def scroll_down(driver, scroll_times=3, delay=0.5):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    for _ in range(scroll_times):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "def next_page(driver):\n",
    "    try:\n",
    "        previous_page = driver.find_element(By.CSS_SELECTOR, 'li.active').text\n",
    "        next_btn = WebDriverWait(driver, 5).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"span.icon.icon-paging-next\"))\n",
    "        )\n",
    "        driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "        time.sleep(1)\n",
    "        new_page = driver.find_element(By.CSS_SELECTOR, 'li.active').text\n",
    "        if new_page == previous_page:\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"L·ªói ·ªü NextPage\")\n",
    "    return False\n",
    "\n",
    "def get_data(url):\n",
    "    page = 1\n",
    "    crawled_data = []\n",
    "\n",
    "    driver = webdriver.Chrome() \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(f\"üîç ƒêang truy c·∫≠p: {url}\")\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            lambda d: d.execute_script(\"return document.readyState\") == \"complete\"\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            scroll_down(driver)\n",
    "            try:\n",
    "                restaurants = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_all_elements_located((By.CLASS_NAME, 'item-restaurant'))\n",
    "                )\n",
    "            except:\n",
    "                print(f\"Kh√¥ng t√¨m th·∫•y nh√† h√†ng tr√™n trang: {url}\")\n",
    "                break\n",
    "\n",
    "            for restaurant in restaurants:\n",
    "                try:\n",
    "                    address_name = restaurant.find_element(By.CLASS_NAME, 'name-res').text\n",
    "                    address = restaurant.find_element(By.CLASS_NAME, 'address-res').text\n",
    "                    crawled_data.append({\n",
    "                                \"address_name\": address_name,\n",
    "                                \"address\": address,\n",
    "                                \"geometry\": None,\n",
    "                                \"source_id\": 8\n",
    "                                })\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            if not next_page(driver):\n",
    "                print(f\" --> ƒê√£ l·∫•y h·∫øt d·ªØ li·ªáu: {url}\")\n",
    "                break\n",
    "            page += 1\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return insert_update_data(crawled_data)  \n",
    "\n",
    "\n",
    "def crawl():\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        for url in urls:\n",
    "            executor.submit(get_data, url)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    crawl()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
